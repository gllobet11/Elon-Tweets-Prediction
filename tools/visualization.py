import argparse
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import sys
from loguru import logger
import numpy as np

# --- Path Configuration ---
try:
    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
    if project_root not in sys.path:
        sys.path.insert(0, project_root)

    from src.strategy.prob_math import DistributionConverter
    from config.bins_definition import MARKET_BINS
    from config.settings import ALPHA_CANDIDATES
    from src.ingestion.unified_feed import load_unified_data
    from src.processing.feature_eng import FeatureEngineer

    # NOTA: Ya no importamos generate_backtest_predictions porque leeremos el CSV generado
except Exception as e:
    logger.error(f"Error import: {e}")
    sys.exit(1)

# --- CONFIGURATION ---
HISTORICAL_PERFORMANCE_PATH = os.path.join(
    project_root, "data", "processed", "historical_performance.csv"
)
OUTPUT_PLOT_PATH = os.path.join(project_root, "historical_predictions_plot.png")
REGIME_CHANGE_PLOT_PATH = os.path.join(project_root, "regime_change_visualization.png")

NUM_CHANGES = 3
MIN_WEEKS_SEPARATION = 8
OPTIMAL_ALPHA = ALPHA_CANDIDATES[0]
OPTIMAL_DISTRIBUTION = "nbinom"
BINS_CONFIG_LIST = [(k, v["lower"], v["upper"]) for k, v in MARKET_BINS.items()]


def calculate_log_loss_for_row(row: pd.Series, pred_col: str) -> float:
    """Calculates Log Loss for a single row of predictions."""
    mu_pred = row[pred_col]
    y_true = row["y_true"]

    try:
        probs = DistributionConverter.get_bin_probabilities(
            mu_remainder=mu_pred,
            current_actuals=0,
            model_type=OPTIMAL_DISTRIBUTION,
            alpha=OPTIMAL_ALPHA,
            bins_config=BINS_CONFIG_LIST,
        )
    except ValueError:
        return np.nan

    correct_bin = None
    for label, lower, upper in BINS_CONFIG_LIST:
        if lower <= y_true < upper:
            correct_bin = label
            break

    if correct_bin is None:
        return np.nan

    prob_correct = probs.get(correct_bin, 0) + 1e-9
    return -np.log(prob_correct)


def visualize_predictions_from_csv():
    """
    Reads the historical performance CSV generated by visualize_comparison.py
    and plots the confidence intervals and metrics.
    """
    logger.info(
        f"ðŸ“Š Reading historical predictions from {HISTORICAL_PERFORMANCE_PATH}..."
    )

    if not os.path.exists(HISTORICAL_PERFORMANCE_PATH):
        logger.error(
            "Historical CSV not found. Please run `python tools/visualize_comparison.py` first."
        )
        return

    df_hist = pd.read_csv(HISTORICAL_PERFORMANCE_PATH)

    # --- FIX: DetecciÃ³n automÃ¡tica de la columna de fecha ---
    date_col = None
    # Lista de posibles nombres que hemos usado en el proyecto
    candidates = ["week_start", "week_start_date", "ds", "date"]

    for col in candidates:
        if col in df_hist.columns:
            date_col = col
            break

    if date_col is None:
        logger.error(
            f"âŒ No date column found in CSV. Available columns: {df_hist.columns.tolist()}"
        )
        return

    # Normalizamos el nombre a 'week_start_date' para el resto del script
    df_hist["week_start_date"] = pd.to_datetime(df_hist[date_col])
    # --------------------------------------------------------

    df_hist = df_hist.sort_values("week_start_date").set_index("week_start_date")

    # Detectar la columna de predicciÃ³n principal
    pred_cols = [
        c
        for c in df_hist.columns
        if "y_pred" in c and "lower" not in c and "upper" not in c
    ]
    if not pred_cols:
        logger.error("No prediction columns found in CSV.")
        return

    # Preferimos 'y_pred_Optuna_Best' si existe, si no, la primera que haya
    target_pred_col = next((c for c in pred_cols if "Optuna" in c), pred_cols[0])
    logger.info(f"Visualizing metrics for model: {target_pred_col}")

    # Calcular Log Loss
    df_hist["log_loss"] = df_hist.apply(
        lambda row: calculate_log_loss_for_row(row, target_pred_col), axis=1
    )
    avg_log_loss = df_hist["log_loss"].mean()
    rmse = np.sqrt(np.mean((df_hist["y_true"] - df_hist[target_pred_col]) ** 2))

    logger.info(f"Visualizing predictions for {len(df_hist)} weeks.")
    logger.info(f"Average Log Loss: {avg_log_loss:.4f}")
    logger.info(f"RMSE: {rmse:.2f}")

    plt.figure(figsize=(14, 7))
    sns.lineplot(
        data=df_hist,
        x=df_hist.index,
        y="y_true",
        label="Actual Tweets (y_true)",
        marker="o",
        color="black",
        linewidth=2,
    )
    sns.lineplot(
        data=df_hist,
        x=df_hist.index,
        y=target_pred_col,
        label=f"Predicted ({target_pred_col})",
        marker="x",
        linestyle="--",
        color="blue",
    )

    # Intervalos de confianza (si existen en el CSV)
    if "y_pred_lower" in df_hist.columns and "y_pred_upper" in df_hist.columns:
        plt.fill_between(
            df_hist.index,
            df_hist["y_pred_lower"],
            df_hist["y_pred_upper"],
            color="blue",
            alpha=0.1,
            label="Confidence Interval",
        )

    plt.title(f"Historical Predictions Analysis (Metrics for {target_pred_col})")
    plt.xlabel("Week Start Date")
    plt.ylabel("Number of Tweets")
    plt.grid(True, alpha=0.3)
    plt.legend()
    plt.tight_layout()

    plt.savefig(OUTPUT_PLOT_PATH)
    logger.success(f"Plot saved to: {OUTPUT_PLOT_PATH}")


def visualize_regime_change():
    """
    Loads unified data, calculates regime intensity (Z-score) using FeatureEngineer,
    and generates a visualization showing monthly tweet counts and the Z-score time series.
    """
    print("--- Z-Score Based Regime Change Visualization ---")

    try:
        # 1. Load unified data
        df_tweets = load_unified_data()

        # 2. Generate features, including the Z-score
        feat_eng = FeatureEngineer()
        all_features = feat_eng.process_data(df_tweets)

        # 3. Prepare data for visualization
        monthly_counts = all_features["n_tweets"].resample("MS").sum()
        z_score_series = all_features["regime_intensity"].dropna()

        # 4. Generate the visualization
        sns.set_style("whitegrid")
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(18, 12), sharex=True)

        # --- Plot 1: Monthly Tweets ---
        ax1.plot(
            monthly_counts.index,
            monthly_counts.values,
            marker="o",
            linestyle="-",
            label="Tweets per Month",
        )
        ax1.set_title("Elon Musk's Monthly Tweets", fontsize=16)
        ax1.set_ylabel("Number of Tweets")
        ax1.legend()

        # --- Plot 2: Z-Score (Regime Intensity) ---
        ax2.plot(
            z_score_series.index,
            z_score_series.values,
            color="purple",
            label="Regime Intensity (Z-score)",
        )
        # Add threshold lines
        ax2.axhline(2.0, color="r", linestyle="--", lw=1, label="High (+2.0)")
        ax2.axhline(-2.0, color="r", linestyle=":", lw=1, label="Low (-2.0)")

        ax2.set_title("Daily Regime Intensity (Z-score)", fontsize=16)
        ax2.set_ylabel("Z-score")
        ax2.set_xlabel("Date")
        ax2.legend()
        ax2.tick_params(axis="x", rotation=45)

        plt.tight_layout()
        plt.show()

    except Exception as e:
        print(f"\nâŒ Error during regime visualization: {e}")


def main():
    parser = argparse.ArgumentParser(description="Visualization tools.")
    parser.add_argument(
        "--task",
        type=str,
        required=True,
        choices=[
            "visualize_predictions",
            "visualize_regime_change",
        ],
        help="The visualization task to execute.",
    )
    args = parser.parse_args()

    if args.task == "visualize_predictions":
        visualize_predictions_from_csv()
    elif args.task == "visualize_regime_change":
        visualize_regime_change()


if __name__ == "__main__":
    main()
